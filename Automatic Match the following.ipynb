{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Klassway match the foll",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5cJ3XAu86oT"
      },
      "source": [
        "## Extract keywords from story"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSlyy1u_9vA-",
        "outputId": "7801daa8-5702-4498-86af-56c57cdaaa70"
      },
      "source": [
        "# Installing from https://github.com/boudinfl/pke library for Python Keyword extraction\n",
        "# We use a fixed commit as the later changes might break the code. If it was on pip we would have used exact version number.\n",
        "\n",
        "!pip install --quiet git+https://github.com/boudinfl/pke.git@dc4d5f21e0ffe64c4df93c46146d29d1c522476b\n",
        "!pip install --quiet flashtext==2.7\n",
        "!pip install --quiet transformers==2.9.0\n",
        "!pip install --quiet nltk==3.4.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 13.1 MB/s \n",
            "\u001b[?25h  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 635 kB 14.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 880 kB 55.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 53.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 62.7 MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 11.5 MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR6rMLaaM37X",
        "outputId": "b9adbf4e-f062-496f-fee0-4ae7d3bebc1e"
      },
      "source": [
        "# connect your personal google drive to store the trained model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bTE46mP-nYj",
        "outputId": "b1888fb2-7b84-462d-ae31-d1241ce4369a"
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import itertools\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "import pke\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "import traceback\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from flashtext import KeywordProcessor\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvZ2DG299ApF",
        "outputId": "80aece6f-0492-4692-dd1c-cf825bb83bc7"
      },
      "source": [
        "import textwrap\n",
        "# Story source - https://byjus.com/kids-learning/moral-stories-the-lion-and-the-mouse/\n",
        "\n",
        "text = \"\"\" Once upon a time, there lived a lion in the dense Amazon rainforest. While he was sleeping by resting his big head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste. This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.\n",
        "\n",
        "The poor mouse begged the lion to spare her this time and she would pay him back on some other day. Hearing this, the lion was amused and wondered how could such a tiny creature ever help him. But he was in a good mood and in his generosity he finally let the mouse go.\n",
        "\n",
        "A few days later, a hunter set a trap for the lion while the big animal was stalking for prey in the forest. Caught in the toils of a hunter’s net, the lion found it difficult to free himself and roared loudly in anger.\n",
        "\n",
        "As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s net. The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore apart. Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.\n",
        "\n",
        "The lion thanked the little mouse for her help and the mouse reminded him that she had finally repaid the lion for sparing her life before. Thereafter, the lion and the mouse became good friends and lived happily in the forest. \"\"\"\n",
        "\n",
        "wrapper = textwrap.TextWrapper(width=150)\n",
        "word_list = wrapper.wrap(text=text)\n",
        "for element in word_list: \n",
        "  print(element) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Once upon a time, there lived a lion in the dense Amazon rainforest. While he was sleeping by resting his big head on his paws, a tiny little mouse\n",
            "unexpectedly crossed by and ran across the lion’s nose in haste. This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.\n",
            "The poor mouse begged the lion to spare her this time and she would pay him back on some other day. Hearing this, the lion was amused and wondered how\n",
            "could such a tiny creature ever help him. But he was in a good mood and in his generosity he finally let the mouse go.  A few days later, a hunter set\n",
            "a trap for the lion while the big animal was stalking for prey in the forest. Caught in the toils of a hunter’s net, the lion found it difficult to\n",
            "free himself and roared loudly in anger.  As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the\n",
            "hunter’s net. The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore\n",
            "apart. Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.  The lion thanked the little mouse for\n",
            "her help and the mouse reminded him that she had finally repaid the lion for sparing her life before. Thereafter, the lion and the mouse became good\n",
            "friends and lived happily in the forest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSDB9XDd9YBu",
        "outputId": "a0870b7f-a379-41f3-af89-a3270aa5f7e6"
      },
      "source": [
        "def get_keywords(text):\n",
        "    out=[]\n",
        "    try:\n",
        "        # extractor = pke.unsupervised.MultipartiteRank()\n",
        "        extractor = pke.unsupervised.YAKE()\n",
        "        extractor.load_document(input=text)\n",
        "        # pos = {'VERB', 'ADJ', 'NOUN'}\n",
        "        pos ={'NOUN'}\n",
        "        stoplist = list(string.punctuation)\n",
        "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "        stoplist += stopwords.words('english')\n",
        "        extractor.candidate_selection(n=1,pos=pos, stoplist=stoplist)\n",
        "\n",
        "        extractor.candidate_weighting(window=3,\n",
        "                                      stoplist=stoplist,\n",
        "                                      use_stems=False)\n",
        "\n",
        "        keyphrases = extractor.get_n_best(n=30)\n",
        "        \n",
        "\n",
        "        for val in keyphrases:\n",
        "            out.append(val[0])\n",
        "    except:\n",
        "        out = []\n",
        "        traceback.print_exc()\n",
        "\n",
        "    return out\n",
        "\n",
        "keywords = get_keywords(text)[:8]\n",
        "print (\"keywords: \",keywords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keywords:  ['lion', 'mouse', 'amazon', 'net', 'hunter', 'tiny', 'free', 'big']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO3owrXlWObz",
        "outputId": "bb342c57-aba9-4e7e-e2bf-ec5387ae0ed3"
      },
      "source": [
        "sentences = tokenize_sentences(text)\n",
        "print (sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once upon a time, there lived a lion in the dense Amazon rainforest.', 'While he was sleeping by resting his big head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste.', 'This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.', 'The poor mouse begged the lion to spare her this time and she would pay him back on some other day.', 'Hearing this, the lion was amused and wondered how could such a tiny creature ever help him.', 'But he was in a good mood and in his generosity he finally let the mouse go.', 'A few days later, a hunter set a trap for the lion while the big animal was stalking for prey in the forest.', 'Caught in the toils of a hunter’s net, the lion found it difficult to free himself and roared loudly in anger.', 'As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s net.', 'The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore apart.', 'Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.', 'The lion thanked the little mouse for her help and the mouse reminded him that she had finally repaid the lion for sparing her life before.', 'Thereafter, the lion and the mouse became good friends and lived happily in the forest.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvjVX2dYWWNB",
        "outputId": "2a5f1029-30bb-4756-c872-d0a18aaea669"
      },
      "source": [
        "from pprint import pprint\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=False)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "keyword_sentence_mapping = get_sentences_for_keyword(keywords, sentences)\n",
        "pprint (keyword_sentence_mapping)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'amazon': ['Once upon a time, there lived a lion in the dense Amazon '\n",
            "            'rainforest.'],\n",
            " 'big': ['Slowly she made a big hole in the net and soon the lion was able to '\n",
            "         'free himself from the hunter’s trap.',\n",
            "         'A few days later, a hunter set a trap for the lion while the big '\n",
            "         'animal was stalking for prey in the forest.',\n",
            "         'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "         'little mouse unexpectedly crossed by and ran across the lion’s nose '\n",
            "         'in haste.'],\n",
            " 'free': ['Slowly she made a big hole in the net and soon the lion was able to '\n",
            "          'free himself from the hunter’s trap.',\n",
            "          'Caught in the toils of a hunter’s net, the lion found it difficult '\n",
            "          'to free himself and roared loudly in anger.',\n",
            "          'As the mouse was passing by, she heard the roar and found the lion '\n",
            "          'struggling hard to free himself from the hunter’s net.'],\n",
            " 'hunter': ['Slowly she made a big hole in the net and soon the lion was able '\n",
            "            'to free himself from the hunter’s trap.',\n",
            "            'A few days later, a hunter set a trap for the lion while the big '\n",
            "            'animal was stalking for prey in the forest.',\n",
            "            'Caught in the toils of a hunter’s net, the lion found it '\n",
            "            'difficult to free himself and roared loudly in anger.',\n",
            "            'As the mouse was passing by, she heard the roar and found the '\n",
            "            'lion struggling hard to free himself from the hunter’s net.'],\n",
            " 'lion': ['Once upon a time, there lived a lion in the dense Amazon '\n",
            "          'rainforest.',\n",
            "          'This woke up the lion and he laid his huge paw angrily on the tiny '\n",
            "          'mouse to kill her.',\n",
            "          'Thereafter, the lion and the mouse became good friends and lived '\n",
            "          'happily in the forest.',\n",
            "          'Hearing this, the lion was amused and wondered how could such a '\n",
            "          'tiny creature ever help him.',\n",
            "          'The poor mouse begged the lion to spare her this time and she would '\n",
            "          'pay him back on some other day.',\n",
            "          'Slowly she made a big hole in the net and soon the lion was able to '\n",
            "          'free himself from the hunter’s trap.',\n",
            "          'A few days later, a hunter set a trap for the lion while the big '\n",
            "          'animal was stalking for prey in the forest.',\n",
            "          'Caught in the toils of a hunter’s net, the lion found it difficult '\n",
            "          'to free himself and roared loudly in anger.',\n",
            "          'As the mouse was passing by, she heard the roar and found the lion '\n",
            "          'struggling hard to free himself from the hunter’s net.',\n",
            "          'The lion thanked the little mouse for her help and the mouse '\n",
            "          'reminded him that she had finally repaid the lion for sparing her '\n",
            "          'life before.',\n",
            "          'The lion thanked the little mouse for her help and the mouse '\n",
            "          'reminded him that she had finally repaid the lion for sparing her '\n",
            "          'life before.',\n",
            "          'The little creature quickly ran towards the lion’s trap that bound '\n",
            "          'him and she gnawed the net with her sharp teeth until the net tore '\n",
            "          'apart.',\n",
            "          'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "          'little mouse unexpectedly crossed by and ran across the lion’s nose '\n",
            "          'in haste.'],\n",
            " 'mouse': ['But he was in a good mood and in his generosity he finally let the '\n",
            "           'mouse go.',\n",
            "           'This woke up the lion and he laid his huge paw angrily on the tiny '\n",
            "           'mouse to kill her.',\n",
            "           'Thereafter, the lion and the mouse became good friends and lived '\n",
            "           'happily in the forest.',\n",
            "           'The poor mouse begged the lion to spare her this time and she '\n",
            "           'would pay him back on some other day.',\n",
            "           'As the mouse was passing by, she heard the roar and found the lion '\n",
            "           'struggling hard to free himself from the hunter’s net.',\n",
            "           'The lion thanked the little mouse for her help and the mouse '\n",
            "           'reminded him that she had finally repaid the lion for sparing her '\n",
            "           'life before.',\n",
            "           'The lion thanked the little mouse for her help and the mouse '\n",
            "           'reminded him that she had finally repaid the lion for sparing her '\n",
            "           'life before.',\n",
            "           'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "           'little mouse unexpectedly crossed by and ran across the lion’s '\n",
            "           'nose in haste.'],\n",
            " 'net': ['Slowly she made a big hole in the net and soon the lion was able to '\n",
            "         'free himself from the hunter’s trap.',\n",
            "         'Caught in the toils of a hunter’s net, the lion found it difficult '\n",
            "         'to free himself and roared loudly in anger.',\n",
            "         'As the mouse was passing by, she heard the roar and found the lion '\n",
            "         'struggling hard to free himself from the hunter’s net.',\n",
            "         'The little creature quickly ran towards the lion’s trap that bound '\n",
            "         'him and she gnawed the net with her sharp teeth until the net tore '\n",
            "         'apart.',\n",
            "         'The little creature quickly ran towards the lion’s trap that bound '\n",
            "         'him and she gnawed the net with her sharp teeth until the net tore '\n",
            "         'apart.'],\n",
            " 'tiny': ['This woke up the lion and he laid his huge paw angrily on the tiny '\n",
            "          'mouse to kill her.',\n",
            "          'Hearing this, the lion was amused and wondered how could such a '\n",
            "          'tiny creature ever help him.',\n",
            "          'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "          'little mouse unexpectedly crossed by and ran across the lion’s nose '\n",
            "          'in haste.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neRbWQhO4GnG"
      },
      "source": [
        "## Download pretrained BERT WSD Model - Run only once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rELsk4JIMhJ3"
      },
      "source": [
        "Download pre-trained BERT WSD from [here](https://entuedu-my.sharepoint.com/:f:/g/personal/boonpeng001_e_ntu_edu_sg/EiWzblOyyOBDtuO3klUbXoAB3THFzke-2MLWguIXrDopWg?e=08umXD)\n",
        "\n",
        "Click the download button at the top left of the link to download a file named \"bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
        "\n",
        "Place the zip file in your Google drive home folder\n",
        "\n",
        "Original [BERT-WSD repository](https://github.com/BPYap/BERT-WSD). All credits to their awesome pre-trained model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNz0zFZzrXqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d97b85c-4e17-45c7-cc14-05576e5720f4"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "bert_wsd_pytorch = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
        "extract_directory = \"/content/gdrive/My Drive\"\n",
        "\n",
        "extracted_folder = bert_wsd_pytorch.replace(\".zip\",\"\")\n",
        "\n",
        "#  If unzipped folder exists don't unzip again.\n",
        "if not os.path.isdir(extracted_folder):\n",
        "  with zipfile.ZipFile(bert_wsd_pytorch, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_directory)\n",
        "else:\n",
        "  print (extracted_folder,\" is extracted already\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6  is extracted already\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GtYSH2ewtO4"
      },
      "source": [
        "# Run model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnmszaP9zSpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8fdf7ee-3cc2-46d1-95a6-3a947a9524da"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "from transformers import BertModel, BertConfig, BertPreTrainedModel, BertTokenizer\n",
        "\n",
        "class BertWSD(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.ranking_linear = torch.nn.Linear(config.hidden_size, 1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    \n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_dir = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6\"\n",
        "\n",
        "\n",
        "model = BertWSD.from_pretrained(model_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "# add new special token\n",
        "if '[TGT]' not in tokenizer.additional_special_tokens:\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})\n",
        "    assert '[TGT]' in tokenizer.additional_special_tokens\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    \n",
        "model.to(DEVICE)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWSD(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (ranking_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0bWxo4vFUfH",
        "outputId": "f82f0b2f-69d0-487b-d5f6-e4741b39583c"
      },
      "source": [
        "import csv\n",
        "import os\n",
        "from collections import namedtuple\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "import torch\n",
        "from tabulate import tabulate\n",
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "GlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"guid\", \"sentence\", \"sense_keys\", \"glosses\", \"targets\"])\n",
        "BertInput = namedtuple(\"BertInput\", [\"input_ids\", \"input_mask\", \"segment_ids\", \"label_id\"])\n",
        "\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "def _create_features_from_records(records, max_seq_length, tokenizer, cls_token_at_end=False, pad_on_left=False,\n",
        "                                  cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
        "                                  sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
        "                                  cls_token_segment_id=1, pad_token_segment_id=0,\n",
        "                                  mask_padding_with_zero=True, disable_progress_bar=False):\n",
        "    \"\"\" Convert records to list of features. Each feature is a list of sub-features where the first element is\n",
        "        always the feature created from context-gloss pair while the rest of the elements are features created from\n",
        "        context-example pairs (if available)\n",
        "        `cls_token_at_end` define the location of the CLS token:\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    for record in tqdm(records, disable=disable_progress_bar):\n",
        "        tokens_a = tokenizer.tokenize(record.sentence)\n",
        "\n",
        "        sequences = [(gloss, 1 if i in record.targets else 0) for i, gloss in enumerate(record.glosses)]\n",
        "\n",
        "        pairs = []\n",
        "        for seq, label in sequences:\n",
        "            tokens_b = tokenizer.tokenize(seq)\n",
        "\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "\n",
        "            # The convention in BERT is:\n",
        "            # (a) For sequence pairs:\n",
        "            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "            #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "            #\n",
        "            # Where \"type_ids\" are used to indicate whether this is the first\n",
        "            # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "            # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "            # embedding vector (and position vector). This is not *strictly* necessary\n",
        "            # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "            # it easier for the model to learn the concept of sequences.\n",
        "            #\n",
        "            # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "            # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "            # the entire model is fine-tuned.\n",
        "            tokens = tokens_a + [sep_token]\n",
        "            segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "            tokens += tokens_b + [sep_token]\n",
        "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
        "\n",
        "            if cls_token_at_end:\n",
        "                tokens = tokens + [cls_token]\n",
        "                segment_ids = segment_ids + [cls_token_segment_id]\n",
        "            else:\n",
        "                tokens = [cls_token] + tokens\n",
        "                segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "            # tokens are attended to.\n",
        "            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "            # Zero-pad up to the sequence length.\n",
        "            padding_length = max_seq_length - len(input_ids)\n",
        "            if pad_on_left:\n",
        "                input_ids = ([pad_token] * padding_length) + input_ids\n",
        "                input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "                segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "            else:\n",
        "                input_ids = input_ids + ([pad_token] * padding_length)\n",
        "                input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "                segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "            assert len(input_ids) == max_seq_length\n",
        "            assert len(input_mask) == max_seq_length\n",
        "            assert len(segment_ids) == max_seq_length\n",
        "\n",
        "            pairs.append(\n",
        "                BertInput(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label)\n",
        "            )\n",
        "\n",
        "        features.append(pairs)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKbPKBjr-KTp",
        "outputId": "222be8d1-94df-4c9d-ca1c-5eddf04692fb"
      },
      "source": [
        "from pprint import pprint\n",
        "sentence = \"Mark's favourite game is **Cricket**.\"\n",
        "\n",
        "sentence_for_bert = sentence.replace(\"**\",\" [TGT] \")\n",
        "sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
        "\n",
        "print (sentence_for_bert)\n",
        "\n",
        "re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sentence_for_bert)\n",
        "if re_result is None:\n",
        "    print(\"\\nIncorrect input format. Please try again.\")\n",
        "\n",
        "ambiguous_word = re_result.group(1).strip()\n",
        "\n",
        "print (\"Word: \",ambiguous_word)\n",
        "\n",
        "\n",
        "results = dict()\n",
        "\n",
        "# wn_pos = wn.NOUN\n",
        "# for i, synset in enumerate(set(wn.synsets(ambiguous_word, pos=wn_pos))):\n",
        "for i, synset in enumerate(set(wn.synsets(ambiguous_word))):\n",
        "    results[synset] =  synset.definition()\n",
        "\n",
        "pprint (results)\n",
        "\n",
        "sense_keys=[]\n",
        "definitions=[]\n",
        "for sense_key, definition in results.items():\n",
        "    sense_keys.append(sense_key)\n",
        "    definitions.append(definition)\n",
        "\n",
        "\n",
        "print (sense_keys)\n",
        "print (definitions)\n",
        "\n",
        "\n",
        "record = GlossSelectionRecord(\"test\", sentence_for_bert, sense_keys, definitions, [-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mark's favourite game is [TGT] Cricket [TGT] .\n",
            "Word:  Cricket\n",
            "{Synset('cricket.n.01'): 'leaping insect; male makes chirping noises by '\n",
            "                         'rubbing the forewings together',\n",
            " Synset('cricket.n.02'): 'a game played with a ball and bat by two teams of 11 '\n",
            "                         'players; teams take turns trying to score runs',\n",
            " Synset('cricket.v.01'): 'play cricket'}\n",
            "[Synset('cricket.v.01'), Synset('cricket.n.01'), Synset('cricket.n.02')]\n",
            "['play cricket', 'leaping insect; male makes chirping noises by rubbing the forewings together', 'a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix16JsX7fyt1",
        "outputId": "2a4c5ec4-af58-43ac-d74e-f73add02d0a4"
      },
      "source": [
        "features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n",
        "                                          cls_token=tokenizer.cls_token,\n",
        "                                          sep_token=tokenizer.sep_token,\n",
        "                                          cls_token_segment_id=1,\n",
        "                                          pad_token_segment_id=0,\n",
        "                                          disable_progress_bar=True)[0]\n",
        "\n",
        "print (len(features))\n",
        "\n",
        "for ftr in features:\n",
        "  print (tokenizer.convert_ids_to_tokens(ftr.input_ids))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'play', 'cricket', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'leaping', 'insect', ';', 'male', 'makes', 'chi', '##rp', '##ing', 'noises', 'by', 'rubbing', 'the', 'forewings', 'together', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'a', 'game', 'played', 'with', 'a', 'ball', 'and', 'bat', 'by', 'two', 'teams', 'of', '11', 'players', ';', 'teams', 'take', 'turns', 'trying', 'to', 'score', 'runs', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aucvx7VAEhj-",
        "outputId": "7ac6a449-b64f-4108-f8bf-cacbe9a30421"
      },
      "source": [
        "with torch.no_grad():\n",
        "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n",
        "      for i, bert_input in list(enumerate(features)):\n",
        "          logits[i] = model.ranking_linear(\n",
        "              model.bert(\n",
        "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "              )[1]\n",
        "          )\n",
        "      scores = softmax(logits, dim=0)\n",
        "\n",
        "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n",
        "\n",
        "print (\"\\n\")\n",
        "for pred in preds:\n",
        "  print (pred)\n",
        "sense = preds[0][0]\n",
        "meaning = preds[0][1]\n",
        "\n",
        "print (\"\\nMost appropriate sense: \",sense)\n",
        "print (\"Most appropriate meaning: \",meaning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "(Synset('cricket.n.02'), 'a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs', tensor(0.6093, dtype=torch.float64))\n",
            "(Synset('cricket.v.01'), 'play cricket', tensor(0.3907, dtype=torch.float64))\n",
            "(Synset('cricket.n.01'), 'leaping insect; male makes chirping noises by rubbing the forewings together', tensor(9.1672e-06, dtype=torch.float64))\n",
            "\n",
            "Most appropriate sense:  Synset('cricket.n.02')\n",
            "Most appropriate meaning:  a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJSpZRuOF-52"
      },
      "source": [
        "def get_sense(sent):\n",
        "  re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sent)\n",
        "  if re_result is None:\n",
        "      print(\"\\nIncorrect input format. Please try again.\")\n",
        "\n",
        "  ambiguous_word = re_result.group(1).strip()\n",
        "  results = dict()\n",
        "\n",
        "  for i, synset in enumerate(set(wn.synsets(ambiguous_word))):\n",
        "      results[synset] =  synset.definition()\n",
        "\n",
        "  if len(results) ==0:\n",
        "    return None\n",
        "\n",
        "  sense_keys=[]\n",
        "  definitions=[]\n",
        "  for sense_key, definition in results.items():\n",
        "      sense_keys.append(sense_key)\n",
        "      definitions.append(definition)\n",
        "\n",
        "  record = GlossSelectionRecord(\"test\", sent, sense_keys, definitions, [-1])\n",
        "\n",
        "  features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n",
        "                                            cls_token=tokenizer.cls_token,\n",
        "                                            sep_token=tokenizer.sep_token,\n",
        "                                            cls_token_segment_id=1,\n",
        "                                            pad_token_segment_id=0,\n",
        "                                            disable_progress_bar=True)[0]\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n",
        "      for i, bert_input in list(enumerate(features)):\n",
        "          logits[i] = model.ranking_linear(\n",
        "              model.bert(\n",
        "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "              )[1]\n",
        "          )\n",
        "      scores = softmax(logits, dim=0)\n",
        "\n",
        "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n",
        "\n",
        "  sense = preds[0][0]\n",
        "  meaning = preds[0][1]\n",
        "  return sense\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2aOpD1WASMl",
        "outputId": "4ffe612b-1ff7-493f-eafb-89fda2fa3e01"
      },
      "source": [
        "import statistics \n",
        "from statistics import mode \n",
        "import re\n",
        "\n",
        "def get_synsets_for_word (word):\n",
        "  return set(wn.synsets(word))\n",
        "  \n",
        "keyword_best_sense = {}\n",
        "\n",
        "for keyword in  keyword_sentence_mapping:\n",
        "  print (\"\\n\\n\")\n",
        "  print(\"Original word: \",keyword)\n",
        "  try:\n",
        "    identified_synsets=get_synsets_for_word(keyword)\n",
        "  except:\n",
        "    continue\n",
        "  for synset in identified_synsets:\n",
        "    print (synset,\"   \",synset.definition())\n",
        "  top_3_sentences = keyword_sentence_mapping[keyword][:3]\n",
        "  best_senses=[]\n",
        "  for sent in top_3_sentences:\n",
        "    insensitive_keyword = re.compile(re.escape(keyword), re.IGNORECASE)\n",
        "    modified_sentence = insensitive_keyword.sub(\" [TGT] \"+keyword+\" [TGT] \", sent,count=1)\n",
        "    modified_sentence = \" \".join(modified_sentence.split())\n",
        "    print (\"modified sentence \",modified_sentence)\n",
        "    best_sense = get_sense(modified_sentence)\n",
        "    best_senses.append(best_sense)\n",
        "  best_sense = mode(best_senses)\n",
        "  print (\"Best sense: \",best_sense)\n",
        "  defn = best_sense.definition()\n",
        "  print (defn)\n",
        "  keyword_best_sense [keyword] = defn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Original word:  lion\n",
            "Synset('lion.n.02')     a celebrity who is lionized (much sought after)\n",
            "Synset('lion.n.01')     large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
            "Synset('leo.n.01')     (astrology) a person who is born while the sun is in Leo\n",
            "Synset('leo.n.03')     the fifth sign of the zodiac; the sun is in this sign from about July 23 to August 22\n",
            "modified sentence  Once upon a time, there lived a [TGT] lion [TGT] in the dense Amazon rainforest.\n",
            "modified sentence  This woke up the [TGT] lion [TGT] and he laid his huge paw angrily on the tiny mouse to kill her.\n",
            "modified sentence  Thereafter, the [TGT] lion [TGT] and the mouse became good friends and lived happily in the forest.\n",
            "Best sense:  Synset('lion.n.01')\n",
            "large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
            "\n",
            "\n",
            "\n",
            "Original word:  mouse\n",
            "Synset('mouse.v.02')     manipulate the mouse of a computer\n",
            "Synset('sneak.v.01')     to go stealthily or furtively\n",
            "Synset('shiner.n.01')     a swollen bruise caused by a blow to the eye\n",
            "Synset('mouse.n.01')     any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails\n",
            "Synset('mouse.n.03')     person who is quiet or timid\n",
            "Synset('mouse.n.04')     a hand-operated electronic device that controls the coordinates of a cursor on your computer screen as you move it around on a pad; on the bottom of the device is a ball that rolls on the surface of the pad\n",
            "modified sentence  But he was in a good mood and in his generosity he finally let the [TGT] mouse [TGT] go.\n",
            "modified sentence  This woke up the lion and he laid his huge paw angrily on the tiny [TGT] mouse [TGT] to kill her.\n",
            "modified sentence  Thereafter, the lion and the [TGT] mouse [TGT] became good friends and lived happily in the forest.\n",
            "Best sense:  Synset('mouse.n.01')\n",
            "any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails\n",
            "\n",
            "\n",
            "\n",
            "Original word:  amazon\n",
            "Synset('amazon.n.03')     a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\n",
            "Synset('amazon.n.02')     (Greek mythology) one of a nation of women warriors of Scythia (who burned off the right breast in order to use a bow and arrow more effectively)\n",
            "Synset('amazon.n.01')     a large strong and aggressive woman\n",
            "Synset('amazon.n.04')     mainly green tropical American parrots\n",
            "modified sentence  Once upon a time, there lived a lion in the dense [TGT] amazon [TGT] rainforest.\n",
            "Best sense:  Synset('amazon.n.03')\n",
            "a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\n",
            "\n",
            "\n",
            "\n",
            "Original word:  net\n",
            "Synset('net.v.04')     catch with a net\n",
            "Synset('web.v.01')     construct or form a web, as if by weaving\n",
            "Synset('internet.n.01')     a computer network consisting of a worldwide network of computer networks that use the TCP/IP network protocols to facilitate data transmission and exchange\n",
            "Synset('net.v.01')     make as a net profit\n",
            "Synset('net.n.02')     a trap made of netting to catch fish or birds or insects\n",
            "Synset('net.n.05')     game equipment consisting of a strip of netting dividing the playing area in tennis or badminton\n",
            "Synset('net_income.n.01')     the excess of revenues over outlays in a given period of time (including depreciation and other non-cash expenses)\n",
            "Synset('net.n.06')     an open fabric of string or rope or wire woven together at regular intervals\n",
            "Synset('final.s.02')     conclusive in a process or progression\n",
            "Synset('net.a.01')     remaining after all deductions\n",
            "Synset('net.n.04')     a goal lined with netting (as in soccer or hockey)\n",
            "Synset('net.v.02')     yield as a net profit\n",
            "modified sentence  Slowly she made a big hole in the [TGT] net [TGT] and soon the lion was able to free himself from the hunter’s trap.\n",
            "modified sentence  Caught in the toils of a hunter’s [TGT] net [TGT] , the lion found it difficult to free himself and roared loudly in anger.\n",
            "modified sentence  As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s [TGT] net [TGT] .\n",
            "Best sense:  Synset('net.n.02')\n",
            "a trap made of netting to catch fish or birds or insects\n",
            "\n",
            "\n",
            "\n",
            "Original word:  hunter\n",
            "Synset('hunter.n.02')     a person who searches for something\n",
            "Synset('hunter.n.01')     someone who hunts game\n",
            "Synset('orion.n.02')     a constellation on the equator to the east of Taurus; contains Betelgeuse and Rigel\n",
            "Synset('hunter.n.04')     a watch with a hinged metal lid to protect the crystal\n",
            "modified sentence  Slowly she made a big hole in the net and soon the lion was able to free himself from the [TGT] hunter [TGT] ’s trap.\n",
            "modified sentence  A few days later, a [TGT] hunter [TGT] set a trap for the lion while the big animal was stalking for prey in the forest.\n",
            "modified sentence  Caught in the toils of a [TGT] hunter [TGT] ’s net, the lion found it difficult to free himself and roared loudly in anger.\n",
            "Best sense:  Synset('hunter.n.01')\n",
            "someone who hunts game\n",
            "\n",
            "\n",
            "\n",
            "Original word:  tiny\n",
            "Synset('bantam.s.01')     very small\n",
            "modified sentence  This woke up the lion and he laid his huge paw angrily on the [TGT] tiny [TGT] mouse to kill her.\n",
            "modified sentence  Hearing this, the lion was amused and wondered how could such a [TGT] tiny [TGT] creature ever help him.\n",
            "modified sentence  While he was sleeping by resting his big head on his paws, a [TGT] tiny [TGT] little mouse unexpectedly crossed by and ran across the lion’s nose in haste.\n",
            "Best sense:  Synset('bantam.s.01')\n",
            "very small\n",
            "\n",
            "\n",
            "\n",
            "Original word:  free\n",
            "Synset('barren.s.03')     completely wanting or lacking\n",
            "Synset('free.v.05')     make (information) available for publication\n",
            "Synset('free.a.06')     not held in servitude\n",
            "Synset('free.v.06')     free from obligations or duties\n",
            "Synset('free.n.01')     people who are free\n",
            "Synset('dislodge.v.01')     remove or force out from a position\n",
            "Synset('absolve.v.02')     let off the hook\n",
            "Synset('detached.s.06')     not fixed in position\n",
            "Synset('rid.v.01')     relieve from\n",
            "Synset('free.s.04')     not occupied or in use\n",
            "Synset('spare.s.03')     not taken up by scheduled activities\n",
            "Synset('loose.r.01')     without restraint\n",
            "Synset('exempt.v.01')     grant relief or an exemption from a rule or requirement to\n",
            "Synset('free.v.01')     grant freedom to; free from confinement\n",
            "Synset('free.v.07')     free or remove obstruction from\n",
            "Synset('unblock.v.03')     make (assets) available\n",
            "Synset('free.a.01')     able to act at will; not hampered; not under compulsion or restraint\n",
            "Synset('complimentary.s.02')     costing nothing\n",
            "Synset('release.v.08')     part with a possession or right\n",
            "Synset('release.v.09')     release (gas or energy) as a result of a chemical reaction or physical decomposition\n",
            "Synset('free.a.02')     unconstrained or not chemically bound in a molecule or not fixed and capable of relatively unrestricted motion\n",
            "Synset('free.s.09')     not literal\n",
            "modified sentence  Slowly she made a big hole in the net and soon the lion was able to [TGT] free [TGT] himself from the hunter’s trap.\n",
            "modified sentence  Caught in the toils of a hunter’s net, the lion found it difficult to [TGT] free [TGT] himself and roared loudly in anger.\n",
            "modified sentence  As the mouse was passing by, she heard the roar and found the lion struggling hard to [TGT] free [TGT] himself from the hunter’s net.\n",
            "Best sense:  Synset('free.a.01')\n",
            "able to act at will; not hampered; not under compulsion or restraint\n",
            "\n",
            "\n",
            "\n",
            "Original word:  big\n",
            "Synset('big.r.04')     in a major way\n",
            "Synset('adult.s.01')     (of animals) fully developed\n",
            "Synset('big.s.10')     marked by intense physical force\n",
            "Synset('big.s.12')     given or giving freely\n",
            "Synset('big.r.03')     on a grand scale\n",
            "Synset('bad.s.02')     very intense\n",
            "Synset('big.s.13')     in an advanced stage of pregnancy\n",
            "Synset('big.s.06')     prodigious\n",
            "Synset('large.a.01')     above average in size or number or quantity or magnitude or extent\n",
            "Synset('big.s.04')     loud and firm\n",
            "Synset('big.s.11')     generous and understanding and tolerant\n",
            "Synset('big.r.01')     extremely well\n",
            "Synset('big.s.05')     conspicuous in position or importance\n",
            "Synset('boastfully.r.01')     in a boastful manner\n",
            "Synset('boastful.s.01')     exhibiting self-importance\n",
            "Synset('big.s.02')     significant\n",
            "Synset('big.s.08')     feeling self-importance\n",
            "modified sentence  Slowly she made a [TGT] big [TGT] hole in the net and soon the lion was able to free himself from the hunter’s trap.\n",
            "modified sentence  A few days later, a hunter set a trap for the lion while the [TGT] big [TGT] animal was stalking for prey in the forest.\n",
            "modified sentence  While he was sleeping by resting his [TGT] big [TGT] head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste.\n",
            "Best sense:  Synset('large.a.01')\n",
            "above average in size or number or quantity or magnitude or extent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypSVwXu7eoA3",
        "outputId": "90b6060d-f0d5-47fb-b0b8-193977804c7d"
      },
      "source": [
        "pprint (keyword_best_sense)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'amazon': 'a major South American river; arises in the Andes and flows '\n",
            "           \"eastward into the South Atlantic; the world's 2nd longest river \"\n",
            "           '(4000 miles)',\n",
            " 'big': 'above average in size or number or quantity or magnitude or extent',\n",
            " 'free': 'able to act at will; not hampered; not under compulsion or restraint',\n",
            " 'hunter': 'someone who hunts game',\n",
            " 'lion': 'large gregarious predatory feline of Africa and India having a tawny '\n",
            "         'coat with a shaggy mane in the male',\n",
            " 'mouse': 'any of numerous small rodents typically resembling diminutive rats '\n",
            "          'having pointed snouts and small ears on elongated bodies with '\n",
            "          'slender usually hairless tails',\n",
            " 'net': 'a trap made of netting to catch fish or birds or insects',\n",
            " 'tiny': 'very small'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1ZAzdJZZH7h",
        "outputId": "5875dc4f-dbd9-42c7-c1d5-b9d66100cd21"
      },
      "source": [
        "import random \n",
        "from prettytable import PrettyTable\n",
        "x = PrettyTable()\n",
        "all_keywords= list(keyword_best_sense.keys())\n",
        "all_definitions = list(keyword_best_sense.values())\n",
        "random.shuffle(all_keywords)\n",
        "random.shuffle(all_definitions)\n",
        "print (all_keywords)\n",
        "print (all_definitions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lion', 'hunter', 'mouse', 'net', 'tiny', 'big', 'amazon', 'free']\n",
            "['any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails', 'very small', 'a trap made of netting to catch fish or birds or insects', 'able to act at will; not hampered; not under compulsion or restraint', \"a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\", 'above average in size or number or quantity or magnitude or extent', 'large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male', 'someone who hunts game']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "sVIdVRmDjcxn",
        "outputId": "7fbd519b-ee38-4d2b-f56d-c8a45e55d9a3"
      },
      "source": [
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "x.field_names=['Word', \"Definition\"]\n",
        "for word,defn in zip(all_keywords,all_definitions):\n",
        "  x.add_row([word,defn])\n",
        "\n",
        "printmd(\"**Match the following words to their correct meanings.**\")\n",
        "# print (\"\\n\")\n",
        "print (x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Match the following words to their correct meanings.**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|  Word  |                                                                            Definition                                                                           |\n",
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|  lion  | any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails |\n",
            "| hunter |                                                                            very small                                                                           |\n",
            "| mouse  |                                                     a trap made of netting to catch fish or birds or insects                                                    |\n",
            "|  net   |                                               able to act at will; not hampered; not under compulsion or restraint                                              |\n",
            "|  tiny  |             a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)            |\n",
            "|  big   |                                                above average in size or number or quantity or magnitude or extent                                               |\n",
            "| amazon |                             large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male                            |\n",
            "|  free  |                                                                      someone who hunts game                                                                     |\n",
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}